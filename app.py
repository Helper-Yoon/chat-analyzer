import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from openpyxl.utils import get_column_letter
from openpyxl.styles import PatternFill, Font, Alignment
import io

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="SNSì„¼í„° ì±„íŒ…ë¶„ì„",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ì»´íŒ©íŠ¸í•œ ìŠ¤íƒ€ì¼
st.markdown("""
    <style>
    /* ìƒë‹¨ íŒ¨ë”© ì œê±° */
    .block-container {
        padding-top: 1rem;
        padding-bottom: 1rem;
        max-width: 1000px;
    }
    
    /* ì œëª© ë°” ìŠ¤íƒ€ì¼ */
    .title-bar {
        background: linear-gradient(90deg, #004C99 0%, #0066CC 100%);
        color: white;
        padding: 0.8rem 1.5rem;
        border-radius: 5px;
        margin-bottom: 1.5rem;
        display: flex;
        align-items: center;
        justify-content: space-between;
    }
    
    .title-bar h1 {
        margin: 0;
        font-size: 1.5rem;
        font-weight: bold;
    }
    
    /* ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
    .stButton > button {
        background: linear-gradient(90deg, #004C99 0%, #0066CC 100%);
        color: white;
        width: 100%;
        height: 50px;
        font-size: 18px;
        font-weight: bold;
        border: none;
        border-radius: 5px;
        margin-top: 1rem;
    }
    
    .stButton > button:hover {
        background: linear-gradient(90deg, #0066CC 0%, #0080FF 100%);
    }
    
    /* ì™„ë£Œ í˜ì´ì§€ ìŠ¤íƒ€ì¼ */
    .success-container {
        text-align: center;
        padding: 2rem;
        background: #f0f8ff;
        border-radius: 10px;
        border: 2px solid #004C99;
        margin: 2rem 0;
    }
    
    .success-icon {
        font-size: 4rem;
        color: #004C99;
        margin-bottom: 1rem;
    }
    
    /* ì…ë ¥ í•„ë“œ ìŠ¤íƒ€ì¼ */
    .stTextInput > div > div > input {
        border: 1px solid #d0d0d0;
        border-radius: 4px;
        padding: 0.4rem;
    }
    
    /* ì„¹ì…˜ ì œëª© ìŠ¤íƒ€ì¼ */
    h5 {
        color: #004C99;
        border-bottom: 2px solid #e0e0e0;
        padding-bottom: 0.5rem;
        margin-bottom: 0.8rem;
        margin-top: 1rem;
    }
    
    /* ì»¬ëŸ¼ ë‚´ ë¼ë²¨ ìŠ¤íƒ€ì¼ */
    .label-text {
        font-weight: 600;
        color: #333;
        display: flex;
        align-items: center;
        height: 38px;
    }
    
    /* ì„¹ì…˜ ê°„ê²© ì¤„ì´ê¸° */
    .element-container {
        margin-bottom: 0.5rem !important;
    }
    </style>
""", unsafe_allow_html=True)

class CollaborationAnalyzer:
    def __init__(self):
        if 'analysis_complete' not in st.session_state:
            st.session_state.analysis_complete = False
        if 'result_file' not in st.session_state:
            st.session_state.result_file = None
        if 'show_result_page' not in st.session_state:
            st.session_state.show_result_page = False

    def load_and_process_data(self, file, start_date_str, end_date_str):
        try:
            # ì—‘ì…€ íŒŒì¼ ë¡œë”©
            all_sheets = pd.read_excel(file, sheet_name=None, engine='openpyxl')
            
            required_sheets = ['UserChat data', 'Message data', 'Manager data']
            sheet_data = {core_name: [] for core_name in required_sheets}
            
            for sheet_name, df in all_sheets.items():
                for core_name in required_sheets:
                    if core_name in sheet_name:
                        sheet_data[core_name].append(df)
            
            if not all(sheet_data.values()):
                st.error("í•„ìˆ˜ ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None

            # ì‹œíŠ¸ í†µí•©
            user_chat_df = pd.concat(sheet_data['UserChat data'], ignore_index=True).drop_duplicates(subset=['id'])
            message_df = pd.concat(sheet_data['Message data'], ignore_index=True).drop_duplicates(subset=['chatId', 'personId', 'createdAt', 'plainText'])
            manager_df = pd.concat(sheet_data['Manager data'], ignore_index=True).drop_duplicates(subset=['id'])

            # ID ì •ì œ
            def clean_id(series):
                return series.astype(str).str.strip().str.replace(r'\.0$', '', regex=True)

            user_chat_df['id'] = clean_id(user_chat_df['id'])
            user_chat_df['assigneeId'] = clean_id(user_chat_df['assigneeId'])
            message_df['chatId'] = clean_id(message_df['chatId'])
            message_df['personId'] = clean_id(message_df['personId'])
            manager_df['id'] = clean_id(manager_df['id'])
            
            # ë‚ ì§œ í•„í„°ë§
            start_ts = pd.to_datetime(start_date_str)
            end_ts = pd.to_datetime(end_date_str) + pd.DateOffset(days=1)

            user_chat_df['firstOpenedAt'] = pd.to_datetime(user_chat_df['firstOpenedAt'], errors='coerce')
            user_chat_df.dropna(subset=['firstOpenedAt'], inplace=True)
            filtered_user_chat_df = user_chat_df[(user_chat_df['firstOpenedAt'] >= start_ts) & (user_chat_df['firstOpenedAt'] < end_ts)]

            message_df['createdAt'] = pd.to_datetime(message_df['createdAt'], errors='coerce')
            message_df.dropna(subset=['createdAt'], inplace=True)
            filtered_message_df = message_df[(message_df['createdAt'] >= start_ts) & (message_df['createdAt'] < end_ts)]
            
            if filtered_message_df.empty:
                st.error("ì„ íƒëœ ê¸°ê°„ ë‚´ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # ë°ì´í„° ë³‘í•©
            merged_df = pd.merge(filtered_message_df, user_chat_df[['id', 'assigneeId']], left_on='chatId', right_on='id', how='left').dropna(subset=['assigneeId'])
            merged_df = pd.merge(merged_df, manager_df[['id', 'name']], left_on='personId', right_on='id', how='left', suffixes=('', '_manager')).rename(columns={'name': 'authorName'}).dropna(subset=['authorName'])
            
            return {'merged': merged_df, 'user_chat': filtered_user_chat_df, 'manager': manager_df}

        except Exception as e:
            st.error(f"ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None

    def create_output_excel(self, processed_data, start_date_str, end_date_str, managers_list, exclusion_list):
        df_merged = processed_data['merged']
        user_chat_df = processed_data['user_chat']
        manager_df = processed_data['manager']
        
        output = io.BytesIO()
        
        # ë°ì´í„° ë¶„ë¥˜
        manager_data = df_merged[df_merged['authorName'].isin(managers_list)]
        agent_data = df_merged[(~df_merged['authorName'].isin(managers_list)) & (~df_merged['authorName'].isin(exclusion_list))]

        all_agents = pd.DataFrame({'authorName': agent_data['authorName'].unique()})
        agent_non_assignee = agent_data[agent_data['personId'] != agent_data['assigneeId']]
        
        if not agent_non_assignee.empty:
            collaborated_chats = agent_non_assignee.groupby('authorName')['chatId'].nunique()
        else:
            collaborated_chats = pd.Series(dtype='int64', name='chatId', index=pd.Index([], name='authorName'))

        total_chats = agent_data.groupby('authorName')['chatId'].nunique()
        hir_summary = (collaborated_chats / total_chats).reset_index(name='HIR').fillna(0)
        
        total_msg_counts = agent_data.groupby('authorName').size().reset_index(name='total_messages')
        
        # í•„í„°ë§
        start_date = datetime.strptime(start_date_str, "%Y-%m-%d")
        end_date = datetime.strptime(end_date_str, "%Y-%m-%d")
        analysis_days = (end_date - start_date).days + 1
        min_msg_threshold = analysis_days * 10

        filter_df = pd.merge(all_agents, hir_summary, on='authorName', how='left')
        filter_df = pd.merge(filter_df, total_msg_counts, on='authorName', how='left')
        filter_df.fillna(0, inplace=True)

        filtered_authors_df = filter_df[
            (filter_df['HIR'] > 0) & (filter_df['HIR'] < 1) & 
            (filter_df['total_messages'] > 10) &
            (filter_df['total_messages'] >= min_msg_threshold)
        ]
        
        if filtered_authors_df.empty:
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                pd.DataFrame({'ì•Œë¦¼': ['í•„í„° ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ìƒë‹´ì‚¬ê°€ ì—†ì–´ ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.']}).to_excel(writer, sheet_name='ê²°ê³¼ ì—†ìŒ', index=False)
            output.seek(0)
            return output

        authors_to_keep = filtered_authors_df['authorName'].unique()
        
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            def analyze_group(group_name, group_merged_df, user_chat_df_local, manager_df_local):
                if group_merged_df.empty and group_name == "ìƒë‹´ì‚¬":
                    return pd.DataFrame(), pd.DataFrame()

                authors = pd.DataFrame({'authorName': pd.concat([group_merged_df['authorName'], manager_df_local.loc[manager_df_local['id'].isin(user_chat_df_local['assigneeId']), 'name']]).unique()})
                
                group_non_assignee_df = group_merged_df[group_merged_df['personId'] != group_merged_df['assigneeId']].copy()
                group_assignee_df = group_merged_df[group_merged_df['personId'] == group_merged_df['assigneeId']].copy()

                metrics_df = authors.copy()
                if not group_non_assignee_df.empty:
                    # HIR ê³„ì‚°
                    hir_s = (group_non_assignee_df.groupby('authorName')['chatId'].nunique() / group_merged_df.groupby('authorName')['chatId'].nunique()).reset_index(name='HIR').fillna(0)
                    
                    # IIF ê³„ì‚°
                    chat_lengths = group_merged_df.groupby('chatId').size().to_dict()
                    group_non_assignee_df['chat_length'] = group_non_assignee_df['chatId'].map(chat_lengths)
                    iif_s = group_non_assignee_df.groupby('authorName')['chat_length'].sum().reset_index(name='IIF')
                    
                    # CIS ê³„ì‚°
                    core_keywords = ['ì›”ìš”ê¸ˆ', 'ì‚¬ì€í’ˆ', 'ìœ„ì•½ê¸ˆ', 'ê²°í•©', 'ì„¤ì¹˜ì¼', 'ì„¤ì¹˜ë¹„', 'ì•½ì •', 'ì§€ì›ê¸ˆ', 'í• ì¸', 'í†µì‹ ì‚¬', 'ìš”ê¸ˆì œ', 'ì¸í„°ë„·', 'íœ´ëŒ€í°']
                    keyword_pattern = '|'.join(core_keywords)
                    group_non_assignee_df['cis_flag'] = group_non_assignee_df['plainText'].str.contains(keyword_pattern, na=False).astype(int)
                    cis_s = group_non_assignee_df.groupby('authorName')['cis_flag'].sum().reset_index(name='CIS')

                    # DLS ê³„ì‚°
                    group_non_assignee_df['msg_length'] = group_non_assignee_df['plainText'].str.len()
                    dls_s = group_non_assignee_df.groupby('authorName')['msg_length'].mean().reset_index(name='DLS')
                    
                    # ALS ê³„ì‚°
                    group_non_assignee_df['als_flag'] = group_non_assignee_df['plainText'].str.contains('https://form.ajd.co.kr/', na=False).astype(int)
                    als_s = group_non_assignee_df.groupby('authorName')['als_flag'].sum().reset_index(name='ALS')
                    als_s['ALS'] *= 10

                    for df in [hir_s, iif_s, cis_s, dls_s, als_s]:
                        metrics_df = pd.merge(metrics_df, df, on='authorName', how='left')
                metrics_df.fillna(0, inplace=True)

                # í†µê³„ ê³„ì‚°
                assigned_stats = group_assignee_df.groupby('authorName').agg(
                    ë‹´ë‹¹_ë©”ì‹œì§€_ìˆ˜=('chatId', 'size'),
                    ë‹´ë‹¹_ê¸€ì_ìˆ˜=('plainText', lambda x: x.str.len().sum())
                ).reset_index()
                
                help_stats = group_non_assignee_df.groupby('authorName').agg(
                    ë„ì›€_ìƒë‹´_ìˆ˜=('chatId', 'nunique'),
                    ë„ì›€_ë©”ì‹œì§€_ìˆ˜=('chatId', 'size'),
                    ë„ì›€_ê¸€ì_ìˆ˜=('plainText', lambda x: x.str.len().sum())
                ).reset_index()
                
                author_ids = manager_df_local[manager_df_local['name'].isin(authors['authorName'])]['id']
                assigned_chat_counts = user_chat_df_local[user_chat_df_local['assigneeId'].isin(author_ids)].groupby('assigneeId').agg(
                    ë‹´ë‹¹_ìƒë‹´_ìˆ˜=('id', 'nunique')
                ).reset_index()
                assigned_chat_counts = pd.merge(assigned_chat_counts, manager_df_local[['id', 'name']], left_on='assigneeId', right_on='id').rename(columns={'name': 'authorName'})

                # ì •ì„± ì ìˆ˜ ê³„ì‚°
                def get_base_score(df):
                    if df.empty:
                        return pd.DataFrame(columns=['authorName', 'base_score'])
                    message_counts = df['plainText'].value_counts()
                    df['score'] = df['plainText'].map(lambda x: np.log1p(len(df) / message_counts.get(x, 1)))
                    return df.groupby('authorName')['score'].sum().reset_index(name='base_score')

                base_help_score = get_base_score(group_non_assignee_df)
                base_assigned_score = get_base_score(group_assignee_df)

                # ìµœì¢… ë°ì´í„° ë³‘í•©
                summary_df = pd.merge(authors, assigned_chat_counts[['authorName', 'ë‹´ë‹¹_ìƒë‹´_ìˆ˜']], on='authorName', how='left')
                summary_df = pd.merge(summary_df, assigned_stats, on='authorName', how='left')
                summary_df = pd.merge(summary_df, help_stats, on='authorName', how='left')
                summary_df = pd.merge(summary_df, base_help_score.rename(columns={'base_score': 'base_help_score'}), on='authorName', how='left')
                summary_df = pd.merge(summary_df, base_assigned_score.rename(columns={'base_score': 'base_assigned_score'}), on='authorName', how='left')
                summary_df = pd.merge(summary_df, metrics_df, on='authorName', how='left')
                summary_df.fillna(0, inplace=True)

                # ë³´ì • ê³„ì‚°
                metrics_for_correction = ['ALS']
                for col in metrics_for_correction:
                    min_val, max_val = summary_df[col].min(), summary_df[col].max()
                    if max_val > min_val:
                        summary_df[f'norm_{col}'] = (summary_df[col] - min_val) / (max_val - min_val)
                    else:
                        summary_df[f'norm_{col}'] = 0
                
                als_weight = 3
                summary_df['help_correction'] = summary_df.get('norm_ALS', 0) * als_weight
                summary_df['assigned_correction'] = 0
                
                summary_df['ë„ì›€_ì •ì„±_ì ìˆ˜'] = summary_df.get('base_help_score', 0) * (1 + summary_df['help_correction'])
                summary_df['ë‹´ë‹¹_ì •ì„±_ì ìˆ˜'] = summary_df.get('base_assigned_score', 0) * (1 + summary_df['assigned_correction'])

                total_help_score = summary_df['ë„ì›€_ì •ì„±_ì ìˆ˜'].sum()
                total_assigned_score = summary_df['ë‹´ë‹¹_ì •ì„±_ì ìˆ˜'].sum()
                if total_assigned_score > 0 and total_help_score > 0:
                    ratio_factor = (total_help_score / 3) / total_assigned_score
                    summary_df['ë‹´ë‹¹_ì •ì„±_ì ìˆ˜'] *= ratio_factor
                
                summary_df['ì´_ì •ì„±_ì ìˆ˜'] = summary_df['ë„ì›€_ì •ì„±_ì ìˆ˜'] + summary_df['ë‹´ë‹¹_ì •ì„±_ì ìˆ˜']

                # ìµœì¢… ì»¬ëŸ¼ ì •ë¦¬
                final_cols = ['authorName', 'ë‹´ë‹¹_ìƒë‹´_ìˆ˜', 'ë‹´ë‹¹_ë©”ì‹œì§€_ìˆ˜', 'ë‹´ë‹¹_ê¸€ì_ìˆ˜', 'ë„ì›€_ìƒë‹´_ìˆ˜', 'ë„ì›€_ë©”ì‹œì§€_ìˆ˜', 'ë„ì›€_ê¸€ì_ìˆ˜', 'ë‹´ë‹¹_ì •ì„±_ì ìˆ˜', 'ë„ì›€_ì •ì„±_ì ìˆ˜', 'ì´_ì •ì„±_ì ìˆ˜']
                final_summary = summary_df[final_cols].rename(columns={
                    'authorName': 'ìƒë‹´ì‚¬ëª…', 'ë‹´ë‹¹_ìƒë‹´_ìˆ˜': 'ë‹´ë‹¹ ìƒë‹´ ìˆ˜', 'ë‹´ë‹¹_ë©”ì‹œì§€_ìˆ˜': 'ë‹´ë‹¹ ë©”ì‹œì§€ ìˆ˜',
                    'ë‹´ë‹¹_ê¸€ì_ìˆ˜': 'ë‹´ë‹¹ ê¸€ì ìˆ˜', 'ë„ì›€_ìƒë‹´_ìˆ˜': 'ë„ì›€ ìƒë‹´ ìˆ˜', 'ë„ì›€_ë©”ì‹œì§€_ìˆ˜': 'ë„ì›€ ë©”ì‹œì§€ ìˆ˜',
                    'ë„ì›€_ê¸€ì_ìˆ˜': 'ë„ì›€ ê¸€ì ìˆ˜', 'ë‹´ë‹¹_ì •ì„±_ì ìˆ˜': 'ë‹´ë‹¹ ì •ì„± ì ìˆ˜', 'ë„ì›€_ì •ì„±_ì ìˆ˜': 'ë„ì›€ ì •ì„± ì ìˆ˜',
                    'ì´_ì •ì„±_ì ìˆ˜': 'ì´ ì •ì„± ì ìˆ˜'
                })
                
                metrics_cols = ['authorName', 'HIR', 'IIF', 'CIS', 'DLS', 'ALS']
                final_metrics = summary_df[metrics_cols].rename(columns={
                    'authorName': 'ìƒë‹´ì‚¬ëª…', 'HIR': 'ë„ì›€ ê°œì…ë¥ ', 'IIF': 'ê°œì… ì˜í–¥ë ¥ ê³„ìˆ˜',
                    'CIS': 'ì½˜í…ì¸  ì •ë³´ ì ìˆ˜', 'DLS': 'ì–¸ì–´ ê¹Šì´ ì ìˆ˜', 'ALS': 'ì‹ ì²­ì„œ ë§í¬ ì ìˆ˜'
                })

                return final_summary.round(2), final_metrics.round(2)

            # ê·¸ë£¹ë³„ ë¶„ì„
            agent_summary_df, agent_metrics_df = analyze_group(
                "ìƒë‹´ì‚¬",
                agent_data[agent_data['authorName'].isin(authors_to_keep)],
                user_chat_df[user_chat_df['assigneeId'].isin(manager_df[manager_df['name'].isin(authors_to_keep)]['id'])],
                manager_df
            )
            
            manager_summary_df, _ = analyze_group(
                "ê´€ë¦¬ì",
                manager_data,
                user_chat_df[user_chat_df['assigneeId'].isin(manager_df[manager_df['name'].isin(managers_list)]['id'])],
                manager_df
            )
            
            # ì—‘ì…€ ì‹œíŠ¸ ìƒì„±
            if not agent_summary_df.empty:
                agent_summary_df = agent_summary_df.sort_values(by='ì´ ì •ì„± ì ìˆ˜', ascending=False)
                agent_summary_df.to_excel(writer, sheet_name='ì±„íŒ…ë¶„ì„_ìš”ì•½', index=False)
            
            if not manager_summary_df.empty:
                manager_summary_df = manager_summary_df.sort_values(by='ì´ ì •ì„± ì ìˆ˜', ascending=False)
                manager_summary_df.to_excel(writer, sheet_name='ê´€ë¦¬ì_ë¶„ì„', index=False)
            
            if not agent_metrics_df.empty:
                agent_metrics_df = agent_metrics_df.sort_values(by='ì‹ ì²­ì„œ ë§í¬ ì ìˆ˜', ascending=False)
                agent_metrics_df.to_excel(writer, sheet_name='ì±„íŒ…ë¶„ì„_ì§€í‘œ', index=False)

            # ìŠ¤ì½”ì–´ë³´ë“œ ìƒì„±
            workbook = writer.book
            worksheet = workbook.create_sheet('ìŠ¤ì½”ì–´ë³´ë“œ')
            
            metrics_to_rank = {
                'ë‹´ë‹¹ ìƒë‹´ ìˆ˜': 'ë‹´ë‹¹ ìƒë‹´ ìˆ˜', 'ë‹´ë‹¹ ë©”ì‹œì§€ ìˆ˜': 'ë‹´ë‹¹ ë©”ì‹œì§€ ìˆ˜', 
                'ë„ì›€ ìƒë‹´ ìˆ˜': 'ë„ì›€ ìƒë‹´ ìˆ˜', 'ë„ì›€ ë©”ì‹œì§€ ìˆ˜': 'ë„ì›€ ë©”ì‹œì§€ ìˆ˜',
                'ì´ ì •ì„± ì ìˆ˜': 'ì´ ì •ì„± ì ìˆ˜'
            }
            
            current_row = 1
            for col, title in metrics_to_rank.items():
                if not agent_summary_df.empty:
                    top_5 = agent_summary_df.nlargest(5, col)[['ìƒë‹´ì‚¬ëª…', col]]
                    
                    worksheet.cell(row=current_row, column=1, value=f'--- {title} Top 5 ---')
                    current_row += 1
                    
                    for i in range(len(top_5)):
                        worksheet.cell(row=current_row + i, column=1, value=f"{i+1}ìœ„")
                        worksheet.cell(row=current_row + i, column=2, value=top_5.iloc[i, 0])
                        worksheet.cell(row=current_row + i, column=3, value=top_5.iloc[i, 1])
                    
                    current_row += 6

        output.seek(0)
        return output

# ë©”ì¸ ì•±
def main():
    analyzer = CollaborationAnalyzer()
    
    # ì œëª© ë°”
    st.markdown("""
        <div class="title-bar">
            <div style="display: flex; align-items: center;">
                <span style="font-size: 1.8rem; margin-right: 10px;">ğŸ“Š</span>
                <h1>SNSì„¼í„° ì±„íŒ…ë¶„ì„ í”„ë¡œê·¸ë¨ v1.9</h1>
            </div>
            <span style="font-size: 0.9rem;">ì±„íŒ… ë°ì´í„° í˜‘ì—… ì„±ê³¼ ë¶„ì„</span>
        </div>
    """, unsafe_allow_html=True)
    
    # ë¶„ì„ ì™„ë£Œ í˜ì´ì§€
    if st.session_state.show_result_page:
        st.markdown("""
            <div class="success-container">
                <div class="success-icon">âœ…</div>
                <h2 style="color: #004C99; margin-bottom: 1rem;">ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!</h2>
                <p style="color: #666; margin-bottom: 2rem;">
                    ë¶„ì„ ê²°ê³¼ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.<br>
                    ì•„ë˜ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ Excel íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.
                </p>
            </div>
        """, unsafe_allow_html=True)
        
        # ë‹¤ìš´ë¡œë“œ ì„¹ì…˜
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"SNSì„¼í„°_ì±„íŒ…ë¶„ì„_ê²°ê³¼_{timestamp}.xlsx"
            
            st.download_button(
                label="ğŸ“¥ ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                data=st.session_state.result_file,
                file_name=filename,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                type="primary",
                use_container_width=True
            )
            
            if st.button("ğŸ”„ ìƒˆë¡œìš´ ë¶„ì„ ì‹œì‘", use_container_width=True):
                st.session_state.show_result_page = False
                st.session_state.analysis_complete = False
                st.session_state.result_file = None
                st.rerun()
        
        # ìƒì„±ëœ ì‹œíŠ¸ ì •ë³´
        st.info("""
            ğŸ“„ **ìƒì„±ëœ ì‹œíŠ¸**: 
            ìŠ¤ì½”ì–´ë³´ë“œ | ì±„íŒ…ë¶„ì„_ìš”ì•½ | ê´€ë¦¬ì_ë¶„ì„ | ì±„íŒ…ë¶„ì„_ì§€í‘œ
        """)
    
    # ë©”ì¸ ë¶„ì„ í˜ì´ì§€
    else:
        # 1. íŒŒì¼ ì—…ë¡œë“œ (í•œ ì¤„)
        st.markdown("##### ğŸ“ íŒŒì¼ ì—…ë¡œë“œ")
        uploaded_file = st.file_uploader(
            "Excel íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
            type=['xlsx'],
            help="UserChat, Message, Manager data ì‹œíŠ¸ê°€ í¬í•¨ëœ íŒŒì¼",
            label_visibility="collapsed"
        )
        if uploaded_file:
            st.success(f"âœ… ì—…ë¡œë“œ ì™„ë£Œ: {uploaded_file.name}")
        
        # 2. ë¶„ì„ ê¸°ê°„ (í•œ ì¤„)
        st.markdown("##### ğŸ“… ë¶„ì„ ê¸°ê°„")
        col1, col2, col3 = st.columns([1, 1, 1])
        with col1:
            start_date = st.date_input(
                "ì‹œì‘ì¼",
                value=datetime(2025, 7, 1)
            )
        with col2:
            end_date = st.date_input(
                "ì¢…ë£Œì¼", 
                value=datetime.now() - timedelta(days=1)
            )
        with col3:
            days = (end_date - start_date).days + 1
            st.metric("ë¶„ì„ ì¼ìˆ˜", f"{days}ì¼")
        
        # 3. ì¸ì› ì„¤ì • (ë‘ ì¤„)
        st.markdown("##### ğŸ‘¥ ì¸ì› ì„¤ì •")
        
        # ê´€ë¦¬ì (ì²« ë²ˆì§¸ ì¤„)
        col1, col2 = st.columns([1, 9])
        with col1:
            st.markdown("<div class='label-text'>ê´€ë¦¬ì</div>", unsafe_allow_html=True)
        with col2:
            managers = st.text_input(
                "ê´€ë¦¬ì ëª©ë¡",
                value="ì´ë¯¼ì£¼, ì´ì¢…ë¯¼, ìœ¤ë„ìš°ë¦¬, ê¹€ì‹œì§„, ì†ì§„ìš°",
                placeholder="ê´€ë¦¬ì ì´ë¦„ì„ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì…ë ¥",
                label_visibility="collapsed"
            )
        
        # ì œì™¸ ì¸ì› (ë‘ ë²ˆì§¸ ì¤„)
        col1, col2 = st.columns([1, 9])
        with col1:
            st.markdown("<div class='label-text'>ì œì™¸</div>", unsafe_allow_html=True)
        with col2:
            exclusions = st.text_input(
                "ì œì™¸ ëª©ë¡",
                value="ì±„ì£¼ì€, ì •ìš©ìš±, í•œìŠ¹ìœ¤, ê¹€ì¢…í˜„",
                placeholder="ì œì™¸í•  ì´ë¦„ì„ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì…ë ¥ (ì„ íƒì‚¬í•­)",
                label_visibility="collapsed"
            )
        
        # êµ¬ë¶„ì„ 
        st.markdown("---")
        
        # ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼ (ì „ì²´ ë„ˆë¹„ íŒŒë€ ë°”)
        analyze_button = st.button(
            "ğŸš€ ë¶„ì„ ì‹¤í–‰",
            type="primary",
            use_container_width=True,
            disabled=not uploaded_file
        )
        
        if not uploaded_file:
            st.warning("âš ï¸ ë¶„ì„ì„ ì‹œì‘í•˜ë ¤ë©´ Excel íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        
        # ë¶„ì„ ì‹¤í–‰
        if analyze_button:
            with st.spinner("ë¶„ì„ ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”"):
                # í”„ë¡œê·¸ë ˆìŠ¤ ë°”
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # ì„¤ì • íŒŒì‹±
                status_text.text("ì„¤ì • í™•ì¸ ì¤‘...")
                progress_bar.progress(20)
                managers_list = [name.strip() for name in managers.split(',') if name.strip()]
                exclusion_list = [name.strip() for name in exclusions.split(',') if name.strip()]
                
                # ë°ì´í„° ì²˜ë¦¬
                status_text.text("ë°ì´í„° ë¡œë”© ì¤‘...")
                progress_bar.progress(40)
                processed_data = analyzer.load_and_process_data(
                    uploaded_file,
                    start_date.strftime("%Y-%m-%d"),
                    end_date.strftime("%Y-%m-%d")
                )
                
                if processed_data:
                    # ê²°ê³¼ ìƒì„±
                    status_text.text("ë¶„ì„ ìˆ˜í–‰ ì¤‘...")
                    progress_bar.progress(70)
                    
                    result_file = analyzer.create_output_excel(
                        processed_data,
                        start_date.strftime("%Y-%m-%d"),
                        end_date.strftime("%Y-%m-%d"),
                        managers_list,
                        exclusion_list
                    )
                    
                    status_text.text("ê²°ê³¼ ìƒì„± ì¤‘...")
                    progress_bar.progress(90)
                    
                    st.session_state.analysis_complete = True
                    st.session_state.result_file = result_file
                    st.session_state.show_result_page = True
                    
                    progress_bar.progress(100)
                    status_text.text("ì™„ë£Œ!")
                    
                    # ì™„ë£Œ í˜ì´ì§€ë¡œ ì „í™˜
                    st.rerun()

if __name__ == "__main__":
    main()
