import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from openpyxl.utils import get_column_letter
from openpyxl.styles import PatternFill, Font, Alignment
import io
import base64

# í˜ì´ì§€ ì„¤ì • - ë‹¤í¬ í…Œë§ˆ
st.set_page_config(
    page_title="SNSì„¼í„° ì±„íŒ…ë¶„ì„ í”„ë¡œê·¸ë¨",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# ë‹¤í¬ëª¨ë“œ + ì•„ì •ë‹¹ ë¸”ë£¨ CSS
st.markdown("""
    <style>
    /* ì „ì²´ ë°°ê²½ ë‹¤í¬ëª¨ë“œ */
    .stApp {
        background-color: #0a0a0a;
        color: #ffffff;
    }
    
    /* ë©”ì¸ í—¤ë” */
    .main-header {
        background: linear-gradient(135deg, #004C99 0%, #0066CC 100%);
        padding: 2.5rem;
        border-radius: 15px;
        margin-bottom: 2rem;
        box-shadow: 0 10px 30px rgba(0, 102, 204, 0.3);
        text-align: center;
        border: 1px solid rgba(0, 102, 204, 0.5);
    }
    
    .main-header h1 {
        color: #ffffff;
        font-size: 2.5rem;
        margin-bottom: 0.5rem;
        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
    }
    
    .main-header p {
        color: #b3d9ff;
        font-size: 1.1rem;
    }
    
    /* ì¹´ë“œ ìŠ¤íƒ€ì¼ */
    .card {
        background: #1a1a1a;
        border: 1px solid #004C99;
        border-radius: 10px;
        padding: 1.5rem;
        margin-bottom: 1.5rem;
        box-shadow: 0 4px 15px rgba(0, 102, 204, 0.2);
    }
    
    .card-header {
        color: #4da6ff;
        font-size: 1.3rem;
        font-weight: bold;
        margin-bottom: 1rem;
        border-bottom: 2px solid #004C99;
        padding-bottom: 0.5rem;
    }
    
    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
    .stButton > button {
        background: linear-gradient(135deg, #004C99 0%, #0066CC 100%);
        color: white;
        border: none;
        padding: 0.75rem 2rem;
        font-size: 1.1rem;
        font-weight: bold;
        border-radius: 8px;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(0, 102, 204, 0.3);
        width: 100%;
    }
    
    .stButton > button:hover {
        background: linear-gradient(135deg, #0066CC 0%, #0080ff 100%);
        box-shadow: 0 6px 20px rgba(0, 102, 204, 0.5);
        transform: translateY(-2px);
    }
    
    /* ì…ë ¥ í•„ë“œ ìŠ¤íƒ€ì¼ */
    .stTextInput > div > div > input,
    .stTextArea > div > div > textarea,
    .stDateInput > div > div > input {
        background-color: #2a2a2a;
        color: #ffffff;
        border: 1px solid #004C99;
        border-radius: 5px;
    }
    
    .stTextInput > div > div > input:focus,
    .stTextArea > div > div > textarea:focus {
        border-color: #0066CC;
        box-shadow: 0 0 0 2px rgba(0, 102, 204, 0.2);
    }
    
    /* íŒŒì¼ ì—…ë¡œë” ìŠ¤íƒ€ì¼ */
    .stFileUploader > div {
        background-color: #1a1a1a;
        border: 2px dashed #004C99;
        border-radius: 10px;
        padding: 2rem;
        transition: all 0.3s ease;
    }
    
    .stFileUploader > div:hover {
        border-color: #0066CC;
        background-color: #262626;
        box-shadow: 0 4px 15px rgba(0, 102, 204, 0.2);
    }
    
    /* ë¡œê·¸ ë°•ìŠ¤ ìŠ¤íƒ€ì¼ */
    .log-box {
        background-color: #0d0d0d;
        border: 1px solid #004C99;
        border-radius: 8px;
        padding: 1rem;
        font-family: 'Courier New', monospace;
        color: #4da6ff;
        max-height: 400px;
        overflow-y: auto;
    }
    
    /* ì •ë³´ ë°•ìŠ¤ ìŠ¤íƒ€ì¼ */
    .info-box {
        background: linear-gradient(135deg, #1a1a1a 0%, #262626 100%);
        border-left: 4px solid #0066CC;
        padding: 1.2rem;
        border-radius: 8px;
        margin: 1rem 0;
        box-shadow: 0 2px 10px rgba(0, 102, 204, 0.2);
    }
    
    .info-box h4 {
        color: #4da6ff;
        margin-bottom: 0.5rem;
    }
    
    .info-box ul {
        color: #b3d9ff;
    }
    
    /* Progress bar ìŠ¤íƒ€ì¼ */
    .stProgress > div > div > div > div {
        background-color: #0066CC;
    }
    
    /* Success/Error/Warning ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ */
    .stSuccess {
        background-color: rgba(0, 102, 204, 0.1);
        border: 1px solid #0066CC;
        color: #4da6ff;
    }
    
    .stError {
        background-color: rgba(255, 0, 0, 0.1);
        border: 1px solid #ff4444;
    }
    
    .stWarning {
        background-color: rgba(255, 193, 7, 0.1);
        border: 1px solid #ffc107;
    }
    
    /* íƒ­ ìŠ¤íƒ€ì¼ */
    .stTabs [data-baseweb="tab-list"] {
        background-color: #1a1a1a;
        border-bottom: 2px solid #004C99;
    }
    
    .stTabs [data-baseweb="tab"] {
        color: #b3d9ff;
        background-color: transparent;
    }
    
    .stTabs [aria-selected="true"] {
        background-color: #004C99;
        color: white;
    }
    
    /* Divider ìŠ¤íƒ€ì¼ */
    hr {
        border-color: #004C99;
        opacity: 0.3;
    }
    
    /* ë¼ë²¨ ìŠ¤íƒ€ì¼ */
    label {
        color: #4da6ff !important;
        font-weight: 500;
    }
    
    /* ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ íŠ¹ë³„ ìŠ¤íƒ€ì¼ */
    .download-button {
        background: linear-gradient(135deg, #00cc66 0%, #00ff88 100%);
        animation: pulse 2s infinite;
    }
    
    @keyframes pulse {
        0% {
            box-shadow: 0 0 0 0 rgba(0, 204, 102, 0.7);
        }
        70% {
            box-shadow: 0 0 0 10px rgba(0, 204, 102, 0);
        }
        100% {
            box-shadow: 0 0 0 0 rgba(0, 204, 102, 0);
        }
    }
    
    /* ìŠ¤í¬ë¡¤ë°” ìŠ¤íƒ€ì¼ */
    ::-webkit-scrollbar {
        width: 10px;
        height: 10px;
    }
    
    ::-webkit-scrollbar-track {
        background: #1a1a1a;
    }
    
    ::-webkit-scrollbar-thumb {
        background: #004C99;
        border-radius: 5px;
    }
    
    ::-webkit-scrollbar-thumb:hover {
        background: #0066CC;
    }
    </style>
""", unsafe_allow_html=True)

class CollaborationAnalyzer:
    def __init__(self):
        self.initialize_session_state()

    def initialize_session_state(self):
        if 'analysis_complete' not in st.session_state:
            st.session_state.analysis_complete = False
        if 'result_file' not in st.session_state:
            st.session_state.result_file = None
        if 'log_messages' not in st.session_state:
            st.session_state.log_messages = []
        if 'processing' not in st.session_state:
            st.session_state.processing = False

    def log(self, message):
        timestamp = datetime.now().strftime('%H:%M:%S')
        log_entry = f"[{timestamp}] {message}"
        st.session_state.log_messages.append(log_entry)

    @st.cache_data(show_spinner=False)
    def load_excel_cached(_self, file_bytes, file_name):
        """ì—‘ì…€ íŒŒì¼ì„ ìºì‹œí•˜ì—¬ ë¡œë“œ"""
        return pd.read_excel(io.BytesIO(file_bytes), sheet_name=None, engine='openpyxl')

    def load_and_process_data(self, file, start_date_str, end_date_str):
        try:
            self.log("ğŸ“ ì—‘ì…€ íŒŒì¼ ë¡œë”© ì¤‘...")
            
            # íŒŒì¼ì„ ë°”ì´íŠ¸ë¡œ ì½ì–´ì„œ ìºì‹œ í™œìš©
            file_bytes = file.read()
            file_name = file.name
            all_sheets = self.load_excel_cached(file_bytes, file_name)
            
            required_sheets = ['UserChat data', 'Message data', 'Manager data']
            sheet_data = {core_name: [] for core_name in required_sheets}
            
            for sheet_name, df in all_sheets.items():
                for core_name in required_sheets:
                    if core_name in sheet_name:
                        sheet_data[core_name].append(df)
            
            if not all(sheet_data.values()):
                st.error("âŒ í•„ìˆ˜ ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None

            self.log("ğŸ”„ ì‹œíŠ¸ í†µí•© ë° ì¤‘ë³µ ì œê±° ì¤‘...")
            user_chat_df = pd.concat(sheet_data['UserChat data'], ignore_index=True).drop_duplicates(subset=['id'])
            message_df = pd.concat(sheet_data['Message data'], ignore_index=True).drop_duplicates(subset=['chatId', 'personId', 'createdAt', 'plainText'])
            manager_df = pd.concat(sheet_data['Manager data'], ignore_index=True).drop_duplicates(subset=['id'])

            self.log("ğŸ§¹ ë°ì´í„° ì •ì œ ë° ë³‘í•© ì¤‘...")
            def clean_id(series):
                return series.astype(str).str.strip().str.replace(r'\.0$', '', regex=True)

            user_chat_df['id'] = clean_id(user_chat_df['id'])
            user_chat_df['assigneeId'] = clean_id(user_chat_df['assigneeId'])
            message_df['chatId'] = clean_id(message_df['chatId'])
            message_df['personId'] = clean_id(message_df['personId'])
            manager_df['id'] = clean_id(manager_df['id'])
            
            # ë‚ ì§œ í•„í„°ë§
            start_ts = pd.to_datetime(start_date_str)
            end_ts = pd.to_datetime(end_date_str) + pd.DateOffset(days=1)

            user_chat_df['firstOpenedAt'] = pd.to_datetime(user_chat_df['firstOpenedAt'], errors='coerce')
            user_chat_df.dropna(subset=['firstOpenedAt'], inplace=True)
            filtered_user_chat_df = user_chat_df[(user_chat_df['firstOpenedAt'] >= start_ts) & (user_chat_df['firstOpenedAt'] < end_ts)]
            self.log(f"ğŸ“Š ë‹´ë‹¹ ìƒë‹´ ì§‘ê³„ ëŒ€ìƒ: {len(filtered_user_chat_df):,}ê°œ ìƒë‹´")

            message_df['createdAt'] = pd.to_datetime(message_df['createdAt'], errors='coerce')
            message_df.dropna(subset=['createdAt'], inplace=True)
            filtered_message_df = message_df[(message_df['createdAt'] >= start_ts) & (message_df['createdAt'] < end_ts)]
            self.log(f"ğŸ’¬ ë©”ì‹œì§€ ë¶„ì„ ëŒ€ìƒ: {len(filtered_message_df):,}ê°œ ë©”ì‹œì§€")
            
            if filtered_message_df.empty:
                st.error("ì„ íƒëœ ê¸°ê°„ ë‚´ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            merged_df = pd.merge(filtered_message_df, user_chat_df[['id', 'assigneeId']], left_on='chatId', right_on='id', how='left').dropna(subset=['assigneeId'])
            merged_df = pd.merge(merged_df, manager_df[['id', 'name']], left_on='personId', right_on='id', how='left', suffixes=('', '_manager')).rename(columns={'name': 'authorName'}).dropna(subset=['authorName'])
            
            self.log(f"âœ… ì´ {len(merged_df):,}ê°œì˜ ìœ íš¨ ë©”ì‹œì§€ ë ˆì½”ë“œ ì²˜ë¦¬ë¨")
            return {'merged': merged_df, 'user_chat': filtered_user_chat_df, 'manager': manager_df}

        except Exception as e:
            st.error(f"ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None

    def auto_adjust_columns(self, writer, sheet_name, df, min_width=15):
        worksheet = writer.sheets[sheet_name]
        for idx, col in enumerate(df.columns):
            max_len = len(str(col)) + 4
            try:
                max_in_col = df[col].astype(str).map(len).max()
                if not pd.isna(max_in_col):
                    max_len = max(max_len, int(max_in_col) + 2)
            except Exception:
                pass
            adjusted_width = max(min_width, max_len)
            worksheet.column_dimensions[get_column_letter(idx + 1)].width = adjusted_width

    def style_header(self, writer, sheet_name, df):
        worksheet = writer.sheets[sheet_name]
        header_fill = PatternFill(start_color="004C99", end_color="004C99", fill_type="solid")
        header_font = Font(bold=True, color="FFFFFF")
        center_align = Alignment(horizontal='center', vertical='center')
        for col_idx in range(1, df.shape[1] + 1):
            cell = worksheet.cell(row=1, column=col_idx)
            cell.fill = header_fill
            cell.font = header_font
            cell.alignment = center_align

    @st.cache_data(show_spinner=False)
    def process_analysis(_self, df_merged, user_chat_df, manager_df, managers_list, exclusion_list):
        """ë¶„ì„ ë¡œì§ì„ ìºì‹œí•˜ì—¬ ì²˜ë¦¬"""
        # ê¸°ì¡´ create_output_excelì˜ ë¶„ì„ ë¡œì§ ë¶€ë¶„ë§Œ ë¶„ë¦¬
        return _self._process_analysis_internal(df_merged, user_chat_df, manager_df, managers_list, exclusion_list)

    def _process_analysis_internal(self, df_merged, user_chat_df, manager_df, managers_list, exclusion_list):
        """ì‹¤ì œ ë¶„ì„ ë¡œì§"""
        manager_data = df_merged[df_merged['authorName'].isin(managers_list)]
        agent_data = df_merged[(~df_merged['authorName'].isin(managers_list)) & (~df_merged['authorName'].isin(exclusion_list))]
        
        all_agents = pd.DataFrame({'authorName': agent_data['authorName'].unique()})
        agent_non_assignee = agent_data[agent_data['personId'] != agent_data['assigneeId']]
        
        if not agent_non_assignee.empty:
            collaborated_chats = agent_non_assignee.groupby('authorName')['chatId'].nunique()
        else:
            collaborated_chats = pd.Series(dtype='int64', name='chatId', index=pd.Index([], name='authorName'))

        total_chats = agent_data.groupby('authorName')['chatId'].nunique()
        hir_summary = (collaborated_chats / total_chats).reset_index(name='HIR').fillna(0)
        
        total_msg_counts = agent_data.groupby('authorName').size().reset_index(name='total_messages')
        
        filter_df = pd.merge(all_agents, hir_summary, on='authorName', how='left')
        filter_df = pd.merge(filter_df, total_msg_counts, on='authorName', how='left')
        filter_df.fillna(0, inplace=True)
        
        return {
            'manager_data': manager_data,
            'agent_data': agent_data,
            'filter_df': filter_df,
            'total_msg_counts': total_msg_counts
        }

    def create_output_excel(self, processed_data, start_date_str, end_date_str, managers_list, exclusion_list):
        df_merged = processed_data['merged']
        user_chat_df = processed_data['user_chat']
        manager_df = processed_data['manager']
        
        output = io.BytesIO()
        
        if exclusion_list:
            self.log(f"ğŸš« ì œì™¸ ëª…ë‹¨: {', '.join(exclusion_list)}")

        # ìºì‹œëœ ë¶„ì„ ê²°ê³¼ ì‚¬ìš©
        analysis_result = self.process_analysis(
            df_merged, user_chat_df, manager_df, managers_list, exclusion_list
        )
        
        manager_data = analysis_result['manager_data']
        agent_data = analysis_result['agent_data']
        filter_df = analysis_result['filter_df']
        
        start_date = datetime.strptime(start_date_str, "%Y-%m-%d")
        end_date = datetime.strptime(end_date_str, "%Y-%m-%d")
        analysis_days = (end_date - start_date).days + 1
        min_msg_threshold = analysis_days * 10
        self.log(f"ğŸ“… ë¶„ì„ ê¸°ê°„: {analysis_days}ì¼, ìµœì†Œ ë©”ì‹œì§€ ìˆ˜: {min_msg_threshold}ê°œ")

        self.log(f"ğŸ‘¥ í•„í„°ë§ ì „ ìƒë‹´ì‚¬ ìˆ˜: {len(filter_df)}ëª…")
        filtered_authors_df = filter_df[
            (filter_df['HIR'] > 0) & (filter_df['HIR'] < 1) & 
            (filter_df['total_messages'] > 10) &
            (filter_df['total_messages'] >= min_msg_threshold)
        ]
        self.log(f"ğŸ‘¥ í•„í„°ë§ í›„ ìƒë‹´ì‚¬ ìˆ˜: {len(filtered_authors_df)}ëª…")
        
        if filtered_authors_df.empty:
            self.log("âš ï¸ í•„í„°ë§ í›„ ë¶„ì„ ëŒ€ìƒ ìƒë‹´ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                pd.DataFrame({'ì•Œë¦¼': ['í•„í„° ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ìƒë‹´ì‚¬ê°€ ì—†ì–´ ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.']}).to_excel(writer, sheet_name='ê²°ê³¼ ì—†ìŒ', index=False)
            output.seek(0)
            return output

        authors_to_keep = filtered_authors_df['authorName'].unique()
        
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            def analyze_group(group_name, group_merged_df, user_chat_df_local, manager_df_local):
                self.log(f"ğŸ” '{group_name}' ê·¸ë£¹ ë¶„ì„ ì¤‘...")
                if group_merged_df.empty and group_name == "ìƒë‹´ì‚¬":
                    return pd.DataFrame(), pd.DataFrame()

                authors = pd.DataFrame({'authorName': pd.concat([group_merged_df['authorName'], manager_df_local.loc[manager_df_local['id'].isin(user_chat_df_local['assigneeId']), 'name']]).unique()})
                
                group_non_assignee_df = group_merged_df[group_merged_df['personId'] != group_merged_df['assigneeId']].copy()
                group_assignee_df = group_merged_df[group_merged_df['personId'] == group_merged_df['assigneeId']].copy()

                metrics_df = authors.copy()
                if not group_non_assignee_df.empty:
                    hir_s = (group_non_assignee_df.groupby('authorName')['chatId'].nunique() / group_merged_df.groupby('authorName')['chatId'].nunique()).reset_index(name='HIR').fillna(0)
                    chat_lengths = group_merged_df.groupby('chatId').size().to_dict()
                    group_non_assignee_df['chat_length'] = group_non_assignee_df['chatId'].map(chat_lengths)
                    iif_s = group_non_assignee_df.groupby('authorName')['chat_length'].sum().reset_index(name='IIF')
                    
                    core_keywords = ['ì›”ìš”ê¸ˆ', 'ì‚¬ì€í’ˆ', 'ìœ„ì•½ê¸ˆ', 'ê²°í•©', 'ì„¤ì¹˜ì¼', 'ì„¤ì¹˜ë¹„', 'ì•½ì •', 'ì§€ì›ê¸ˆ', 'í• ì¸', 'í†µì‹ ì‚¬', 'ìš”ê¸ˆì œ', 'ì¸í„°ë„·', 'íœ´ëŒ€í°']
                    keyword_pattern = '|'.join(core_keywords)
                    group_non_assignee_df['cis_flag'] = group_non_assignee_df['plainText'].str.contains(keyword_pattern, na=False).astype(int)
                    cis_s = group_non_assignee_df.groupby('authorName')['cis_flag'].sum().reset_index(name='CIS')

                    group_non_assignee_df['msg_length'] = group_non_assignee_df['plainText'].str.len()
                    dls_s = group_non_assignee_df.groupby('authorName')['msg_length'].mean().reset_index(name='DLS')
                    
                    group_non_assignee_df['als_flag'] = group_non_assignee_df['plainText'].str.contains('https://form.ajd.co.kr/', na=False).astype(int)
                    als_s = group_non_assignee_df.groupby('authorName')['als_flag'].sum().reset_index(name='ALS')
                    als_s['ALS'] *= 10

                    for df in [hir_s, iif_s, cis_s, dls_s, als_s]:
                        metrics_df = pd.merge(metrics_df, df, on='authorName', how='left')
                metrics_df.fillna(0, inplace=True)

                assigned_stats = group_assignee_df.groupby('authorName').agg(
                    ë‹´ë‹¹_ë©”ì‹œì§€_ìˆ˜=('chatId', 'size'),
                    ë‹´ë‹¹_ê¸€ì_ìˆ˜=('plainText', lambda x: x.str.len().sum())
                ).reset_index()
                
                help_stats = group_non_assignee_df.groupby('authorName').agg(
                    ë„ì›€_ìƒë‹´_ìˆ˜=('chatId', 'nunique'),
                    ë„ì›€_ë©”ì‹œì§€_ìˆ˜=('chatId', 'size'),
                    ë„ì›€_ê¸€ì_ìˆ˜=('plainText', lambda x: x.str.len().sum())
                ).reset_index()
                
                author_ids = manager_df_local[manager_df_local['name'].isin(authors['authorName'])]['id']
                assigned_chat_counts = user_chat_df_local[user_chat_df_local['assigneeId'].isin(author_ids)].groupby('assigneeId').agg(
                    ë‹´ë‹¹_ìƒë‹´_ìˆ˜=('id', 'nunique')
                ).reset_index()
                assigned_chat_counts = pd.merge(assigned_chat_counts, manager_df_local[['id', 'name']], left_on='assigneeId', right_on='id').rename(columns={'name': 'authorName'})

                def get_base_score(df):
                    if df.empty:
                        return pd.DataFrame(columns=['authorName', 'base_score'])
                    message_counts = df['plainText'].value_counts()
                    df['score'] = df['plainText'].map(lambda x: np.log1p(len(df) / message_counts.get(x, 1)))
                    return df.groupby('authorName')['score'].sum().reset_index(name='base_score')

                base_help_score = get_base_score(group_non_assignee_df)
                base_assigned_score = get_base_score(group_assignee_df)

                summary_df = pd.merge(authors, assigned_chat_counts[['authorName', 'ë‹´ë‹¹_ìƒë‹´_ìˆ˜']], on='authorName', how='left')
                summary_df = pd.merge(summary_df, assigned_stats, on='authorName', how='left')
                summary_df = pd.merge(summary_df, help_stats, on='authorName', how='left')
                summary_df = pd.merge(summary_df, base_help_score.rename(columns={'base_score': 'base_help_score'}), on='authorName', how='left')
                summary_df = pd.merge(summary_df, base_assigned_score.rename(columns={'base_score': 'base_assigned_score'}), on='authorName', how='left')
                summary_df = pd.merge(summary_df, metrics_df, on='authorName', how='left')
                summary_df.fillna(0, inplace=True)

                metrics_for_correction = ['ALS']
                for col in metrics_for_correction:
                    min_val, max_val = summary_df[col].min(), summary_df[col].max()
                    if max_val > min_val:
                        summary_df[f'norm_{col}'] = (summary_df[col] - min_val) / (max_val - min_val)
                    else:
                        summary_df[f'norm_{col}'] = 0
                
                als_weight = 3
                summary_df['help_correction'] = summary_df.get('norm_ALS', 0) * als_weight
                summary_df['assigned_correction'] = 0
                
                summary_df['ë„ì›€_ì •ì„±_ì ìˆ˜'] = summary_df.get('base_help_score', 0) * (1 + summary_df['help_correction'])
                summary_df['ë‹´ë‹¹_ì •ì„±_ì ìˆ˜'] = summary_df.get('base_assigned_score', 0) * (1 + summary_df['assigned_correction'])

                total_help_score = summary_df['ë„ì›€_ì •ì„±_ì ìˆ˜'].sum()
                total_assigned_score = summary_df['ë‹´ë‹¹_ì •ì„±_ì ìˆ˜'].sum()
                if total_assigned_score > 0 and total_help_score > 0:
                    ratio_factor = (total_help_score / 3) / total_assigned_score
                    summary_df['ë‹´ë‹¹_ì •ì„±_ì ìˆ˜'] *= ratio_factor
                
                summary_df['ì´_ì •ì„±_ì ìˆ˜'] = summary_df['ë„ì›€_ì •ì„±_ì ìˆ˜'] + summary_df['ë‹´ë‹¹_ì •ì„±_ì ìˆ˜']

                final_cols = ['authorName', 'ë‹´ë‹¹_ìƒë‹´_ìˆ˜', 'ë‹´ë‹¹_ë©”ì‹œì§€_ìˆ˜', 'ë‹´ë‹¹_ê¸€ì_ìˆ˜', 'ë„ì›€_ìƒë‹´_ìˆ˜', 'ë„ì›€_ë©”ì‹œì§€_ìˆ˜', 'ë„ì›€_ê¸€ì_ìˆ˜', 'ë‹´ë‹¹_ì •ì„±_ì ìˆ˜', 'ë„ì›€_ì •ì„±_ì ìˆ˜', 'ì´_ì •ì„±_ì ìˆ˜']
                final_summary = summary_df[final_cols].rename(columns={
                    'authorName': 'ìƒë‹´ì‚¬ëª…', 'ë‹´ë‹¹_ìƒë‹´_ìˆ˜': 'ë‹´ë‹¹ ìƒë‹´ ìˆ˜', 'ë‹´ë‹¹_ë©”ì‹œì§€_ìˆ˜': 'ë‹´ë‹¹ ë©”ì‹œì§€ ìˆ˜',
                    'ë‹´ë‹¹_ê¸€ì_ìˆ˜': 'ë‹´ë‹¹ ê¸€ì ìˆ˜', 'ë„ì›€_ìƒë‹´_ìˆ˜': 'ë„ì›€ ìƒë‹´ ìˆ˜', 'ë„ì›€_ë©”ì‹œì§€_ìˆ˜': 'ë„ì›€ ë©”ì‹œì§€ ìˆ˜',
                    'ë„ì›€_ê¸€ì_ìˆ˜': 'ë„ì›€ ê¸€ì ìˆ˜', 'ë‹´ë‹¹_ì •ì„±_ì ìˆ˜': 'ë‹´ë‹¹ ì •ì„± ì ìˆ˜', 'ë„ì›€_ì •ì„±_ì ìˆ˜': 'ë„ì›€ ì •ì„± ì ìˆ˜',
                    'ì´_ì •ì„±_ì ìˆ˜': 'ì´ ì •ì„± ì ìˆ˜'
                })
                
                metrics_cols = ['authorName', 'HIR', 'IIF', 'CIS', 'DLS', 'ALS']
                final_metrics = summary_df[metrics_cols].rename(columns={
                    'authorName': 'ìƒë‹´ì‚¬ëª…', 'HIR': 'ë„ì›€ ê°œì…ë¥ ', 'IIF': 'ê°œì… ì˜í–¥ë ¥ ê³„ìˆ˜',
                    'CIS': 'ì½˜í…ì¸  ì •ë³´ ì ìˆ˜', 'DLS': 'ì–¸ì–´ ê¹Šì´ ì ìˆ˜', 'ALS': 'ì‹ ì²­ì„œ ë§í¬ ì ìˆ˜'
                })

                return final_summary.round(2), final_metrics.round(2)

            # ê·¸ë£¹ë³„ ë¶„ì„ ì‹¤í–‰
            agent_summary_df, agent_metrics_df = analyze_group(
                "ìƒë‹´ì‚¬",
                agent_data[agent_data['authorName'].isin(authors_to_keep)],
                user_chat_df[user_chat_df['assigneeId'].isin(manager_df[manager_df['name'].isin(authors_to_keep)]['id'])],
                manager_df
            )
            
            manager_summary_df, _ = analyze_group(
                "ê´€ë¦¬ì",
                manager_data,
                user_chat_df[user_chat_df['assigneeId'].isin(manager_df[manager_df['name'].isin(managers_list)]['id'])],
                manager_df
            )
            
            # ì—‘ì…€ ì‹œíŠ¸ ìƒì„±
            agent_summary_df = agent_summary_df.sort_values(by='ì´ ì •ì„± ì ìˆ˜', ascending=False)
            agent_summary_df.to_excel(writer, sheet_name='ì±„íŒ…ë¶„ì„_ìš”ì•½', index=False)
            self.style_header(writer, 'ì±„íŒ…ë¶„ì„_ìš”ì•½', agent_summary_df)
            self.auto_adjust_columns(writer, 'ì±„íŒ…ë¶„ì„_ìš”ì•½', agent_summary_df)
            self.log("âœ… 'ì±„íŒ…ë¶„ì„_ìš”ì•½' ì‹œíŠ¸ ìƒì„± ì™„ë£Œ")
            
            if not manager_summary_df.empty:
                manager_summary_df = manager_summary_df.sort_values(by='ì´ ì •ì„± ì ìˆ˜', ascending=False)
                manager_summary_df.to_excel(writer, sheet_name='ê´€ë¦¬ì_ë¶„ì„', index=False)
                self.style_header(writer, 'ê´€ë¦¬ì_ë¶„ì„', manager_summary_df)
                self.auto_adjust_columns(writer, 'ê´€ë¦¬ì_ë¶„ì„', manager_summary_df)
                self.log("âœ… 'ê´€ë¦¬ì_ë¶„ì„' ì‹œíŠ¸ ìƒì„± ì™„ë£Œ")
            
            agent_metrics_df = agent_metrics_df.sort_values(by='ì‹ ì²­ì„œ ë§í¬ ì ìˆ˜', ascending=False)
            agent_metrics_df.to_excel(writer, sheet_name='ì±„íŒ…ë¶„ì„_ì§€í‘œ', index=False)
            self.style_header(writer, 'ì±„íŒ…ë¶„ì„_ì§€í‘œ', agent_metrics_df)
            self.auto_adjust_columns(writer, 'ì±„íŒ…ë¶„ì„_ì§€í‘œ', agent_metrics_df)
            self.log("âœ… 'ì±„íŒ…ë¶„ì„_ì§€í‘œ' ì‹œíŠ¸ ìƒì„± ì™„ë£Œ")

            # ìŠ¤ì½”ì–´ë³´ë“œ ìƒì„±
            self.log("ğŸ“Š 'ìŠ¤ì½”ì–´ë³´ë“œ' ì‹œíŠ¸ ìƒì„± ì¤‘...")
            workbook = writer.book
            worksheet = workbook.create_sheet('ìŠ¤ì½”ì–´ë³´ë“œ')
            
            sheets = writer.book.sheetnames
            writer.book.move_sheet('ìŠ¤ì½”ì–´ë³´ë“œ', offset=-sheets.index('ìŠ¤ì½”ì–´ë³´ë“œ'))
            writer.book.move_sheet('ì±„íŒ…ë¶„ì„_ìš”ì•½', offset=-len(writer.book.sheetnames))
            
            title_font = Font(bold=True, color="FFFFFF", size=11)
            header_font = Font(bold=True, size=10)
            center_align = Alignment(horizontal='center', vertical='center')

            top5_header_fill = PatternFill(start_color="004C99", end_color="004C99", fill_type="solid")
            bottom5_header_fill = PatternFill(start_color="CC0000", end_color="CC0000", fill_type="solid")
            top5_data_fill = PatternFill(start_color="E6F2FF", end_color="E6F2FF", fill_type="solid")
            bottom5_data_fill = PatternFill(start_color="FFE6E6", end_color="FFE6E6", fill_type="solid")
            
            metrics_to_rank = {
                'ë‹´ë‹¹ ìƒë‹´ ìˆ˜': 'ë‹´ë‹¹ ìƒë‹´ ìˆ˜', 'ë‹´ë‹¹ ë©”ì‹œì§€ ìˆ˜': 'ë‹´ë‹¹ ë©”ì‹œì§€ ìˆ˜', 'ë‹´ë‹¹ ê¸€ì ìˆ˜': 'ë‹´ë‹¹ ê¸€ì ìˆ˜',
                'ë„ì›€ ìƒë‹´ ìˆ˜': 'ë„ì›€ ìƒë‹´ ìˆ˜', 'ë„ì›€ ë©”ì‹œì§€ ìˆ˜': 'ë„ì›€ ë©”ì‹œì§€ ìˆ˜', 'ë„ì›€ ê¸€ì ìˆ˜': 'ë„ì›€ ê¸€ì ìˆ˜',
                'ë‹´ë‹¹ ì •ì„± ì ìˆ˜': 'ë‹´ë‹¹ ì •ì„± ì ìˆ˜', 'ë„ì›€ ì •ì„± ì ìˆ˜': 'ë„ì›€ ì •ì„± ì ìˆ˜', 'ì´ ì •ì„± ì ìˆ˜': 'ì´ ì •ì„± ì ìˆ˜'
            }
            
            current_row = 1
            for col, title in metrics_to_rank.items():
                top_5 = agent_summary_df.nlargest(5, col)[['ìƒë‹´ì‚¬ëª…', col]]
                bottom_5 = agent_summary_df.nsmallest(5, col)[['ìƒë‹´ì‚¬ëª…', col]]

                worksheet.merge_cells(start_row=current_row, start_column=1, end_row=current_row, end_column=5)
                cell = worksheet.cell(row=current_row, column=1, value=f'--- {title} ìˆœìœ„ ---')
                cell.font = header_font
                cell.alignment = center_align
                current_row += 1
                
                headers = ['Top 5', 'ì ìˆ˜', '', 'Bottom 5', 'ì ìˆ˜']
                fills = [top5_header_fill, top5_header_fill, None, bottom5_header_fill, bottom5_header_fill]
                
                for c_idx, value in enumerate(headers):
                    if value:
                        cell = worksheet.cell(row=current_row, column=c_idx + 1, value=value)
                        cell.font = title_font
                        cell.alignment = center_align
                        cell.fill = fills[c_idx]
                current_row += 1
                
                for i in range(5):
                    row_to_write = current_row + i
                    if i < len(top_5):
                        cell_name = worksheet.cell(row=row_to_write, column=1, value=top_5.iloc[i, 0])
                        cell_score = worksheet.cell(row=row_to_write, column=2, value=top_5.iloc[i, 1])
                        cell_name.fill = top5_data_fill
                        cell_score.fill = top5_data_fill
                    
                    if i < len(bottom_5):
                        cell_name = worksheet.cell(row=row_to_write, column=4, value=bottom_5.iloc[i, 0])
                        cell_score = worksheet.cell(row=row_to_write, column=5, value=bottom_5.iloc[i, 1])
                        cell_name.fill = bottom5_data_fill
                        cell_score.fill = bottom5_data_fill
                
                current_row += 6

            worksheet.column_dimensions[get_column_letter(1)].width = 20
            worksheet.column_dimensions[get_column_letter(2)].width = 15
            worksheet.column_dimensions[get_column_letter(3)].width = 5
            worksheet.column_dimensions[get_column_letter(4)].width = 20
            worksheet.column_dimensions[get_column_letter(5)].width = 15
            self.log("âœ… 'ìŠ¤ì½”ì–´ë³´ë“œ' ì‹œíŠ¸ ìƒì„± ì™„ë£Œ")

            # ìƒì„¸ ë©”ì‹œì§€ ë‚´ì—­ ì‹œíŠ¸ (ê°„ì†Œí™”)
            non_assignee_df = df_merged[df_merged['personId'] != df_merged['assigneeId']]
            assignee_df = df_merged[df_merged['personId'] == df_merged['assigneeId']]

            details_collab = non_assignee_df[non_assignee_df['authorName'].isin(authors_to_keep)]
            if not details_collab.empty:
                details_collab = details_collab[['authorName', 'chatId', 'createdAt', 'plainText']].copy()
                details_collab.rename(columns={
                    'authorName': 'ìƒë‹´ì‚¬ëª…', 'chatId': 'ì±„íŒ…ë°© ID',
                    'createdAt': 'ë©”ì‹œì§€ ì‘ì„±ì¼ì‹œ', 'plainText': 'ë©”ì‹œì§€ ì›ë¬¸'
                }, inplace=True)
                details_collab = details_collab.sort_values(by=['ìƒë‹´ì‚¬ëª…', 'ë©”ì‹œì§€ ì‘ì„±ì¼ì‹œ'])
                details_collab.to_excel(writer, sheet_name='ìƒì„¸ ë©”ì‹œì§€ ë‚´ì—­_ë„ì›€', index=False)
                self.style_header(writer, 'ìƒì„¸ ë©”ì‹œì§€ ë‚´ì—­_ë„ì›€', details_collab)
                self.auto_adjust_columns(writer, 'ìƒì„¸ ë©”ì‹œì§€ ë‚´ì—­_ë„ì›€', details_collab)

            details_assignee = assignee_df[assignee_df['authorName'].isin(authors_to_keep)]
            if not details_assignee.empty:
                details_assignee = details_assignee[['authorName', 'chatId', 'createdAt', 'plainText']].copy()
                details_assignee.rename(columns={
                    'authorName': 'ìƒë‹´ì‚¬ëª…', 'chatId': 'ì±„íŒ…ë°© ID',
                    'createdAt': 'ë©”ì‹œì§€ ì‘ì„±ì¼ì‹œ', 'plainText': 'ë©”ì‹œì§€ ì›ë¬¸'
                }, inplace=True)
                details_assignee = details_assignee.sort_values(by=['ìƒë‹´ì‚¬ëª…', 'ë©”ì‹œì§€ ì‘ì„±ì¼ì‹œ'])
                details_assignee.to_excel(writer, sheet_name='ìƒì„¸ ë©”ì‹œì§€ ë‚´ì—­_ë‹´ë‹¹ì', index=False)
                self.style_header(writer, 'ìƒì„¸ ë©”ì‹œì§€ ë‚´ì—­_ë‹´ë‹¹ì', details_assignee)
                self.auto_adjust_columns(writer, 'ìƒì„¸ ë©”ì‹œì§€ ë‚´ì—­_ë‹´ë‹¹ì', details_assignee)

            # ë„ì›€ë§ ì‹œíŠ¸
            self.log("ğŸ“ 'ë„ì›€ë§' ì‹œíŠ¸ ìƒì„± ì¤‘...")
            help_data = {
                'êµ¬ë¶„': ['ì •ëŸ‰ ì§€í‘œ', 'ì •ëŸ‰ ì§€í‘œ', 'ì •ì„± ì§€í‘œ', 'ì •ì„± ì§€í‘œ', 'ì •ì„± ì§€í‘œ', 'ì •ì„± ì ìˆ˜', 'ì •ì„± ì ìˆ˜', 'ì •ì„± ì ìˆ˜'],
                'ì§€í‘œëª…': ['HIR (ë„ì›€ ê°œì…ë¥ )', 'IIF (ê°œì… ì˜í–¥ë ¥ ê³„ìˆ˜)', 'CIS (ì½˜í…ì¸  ì •ë³´ ì ìˆ˜)',
                          'DLS (ì–¸ì–´ ê¹Šì´ ì ìˆ˜)', 'ALS (ì‹ ì²­ì„œ ë§í¬ ì ìˆ˜)', 'ë„ì›€ ì •ì„± ì ìˆ˜',
                          'ë‹´ë‹¹ ì •ì„± ì ìˆ˜', 'ì´ ì •ì„± ì ìˆ˜'],
                'ì •ì˜': [
                    'í•œ ìƒë‹´ì‚¬ê°€ ì°¸ì—¬í•œ ì „ì²´ ìƒë‹´ ì¤‘, í˜‘ì—…ìë¡œ ì°¸ì—¬í•œ ìƒë‹´ì˜ ë¹„ìœ¨',
                    'ë‹¨ìˆœ ë©”ì‹œì§€ ìˆ˜ë¥¼ ë„˜ì–´, ì–¼ë§ˆë‚˜ ê¸¸ê³  ë³µì¡í•œ ëŒ€í™”ì— ê°œì…í–ˆëŠ”ì§€ë¥¼ ê°€ì¤‘ì¹˜ë¡œ í‰ê°€',
                    'ë„ì›€ ë©”ì‹œì§€ ì¤‘, ì‚¬ì „ì— ì •ì˜ëœ í•µì‹¬ ìƒí’ˆ í‚¤ì›Œë“œë¥¼ í¬í•¨í•œ ë©”ì‹œì§€ì˜ ê°œìˆ˜',
                    'ë„ì›€ ë©”ì‹œì§€ 1ê°œë‹¹ í‰ê·  ê¸€ì ê¸¸ì´',
                    'ë„ì›€ ë©”ì‹œì§€ì—ì„œ ì‹ ì²­ì„œ ë§í¬ë¥¼ ë°œì†¡í•œ íšŸìˆ˜ì— ê¸°ë°˜í•œ ì ìˆ˜',
                    'ë„ì›€ ë©”ì‹œì§€ì˜ í¬ì†Œì„±ê³¼ ALS ë³´ì •ì¹˜ë¥¼ ë°˜ì˜í•œ ì§ˆì  ê¸°ì—¬ë„ ì ìˆ˜',
                    'ë‹´ë‹¹ ë©”ì‹œì§€ì˜ í¬ì†Œì„± ì ìˆ˜ë¥¼ ë°˜ì˜í•˜ê³ , ë„ì›€ ì •ì„± ì ìˆ˜ì™€ì˜ ë¹„ìœ¨ì„ ì¡°ì •í•œ ì§ˆì  ê¸°ì—¬ë„ ì ìˆ˜',
                    'ë„ì›€ ì •ì„± ì ìˆ˜ì™€ ë‹´ë‹¹ ì •ì„± ì ìˆ˜ì˜ í•©ì‚°'
                ],
                'ì‚°ì‹': [
                    'í˜‘ì—… ì°¸ì—¬ ìƒë‹´ ê±´ìˆ˜ / ì´ ì°¸ì—¬ ìƒë‹´ ê±´ìˆ˜',
                    'Î£ (í˜‘ì—… ì°¸ì—¬í•œ ê° ìƒë‹´ ê±´ì˜ ì „ì²´ ë©”ì‹œì§€ ìˆ˜)',
                    'Î£ (ë„ì›€ ë©”ì‹œì§€ ë‚´ í•µì‹¬ í‚¤ì›Œë“œ í¬í•¨ ê°œìˆ˜)',
                    'ë„ì›€ ë©”ì‹œì§€ ì´ ê¸€ì ìˆ˜ / ë„ì›€ ë©”ì‹œì§€ ì´ ê°œìˆ˜',
                    'Î£ (ì‹ ì²­ì„œ ë§í¬ ë°œì†¡ íšŸìˆ˜) * 10ì ',
                    'ê¸°ë³¸ ì ìˆ˜ * (1 + (ì •ê·œí™” ALS * 3))',
                    'ê¸°ë³¸ ì ìˆ˜ * ë¹„ìœ¨ ì¡°ì • ê³„ìˆ˜',
                    'ë„ì›€ ì •ì„± ì ìˆ˜ + ë‹´ë‹¹ ì •ì„± ì ìˆ˜'
                ]
            }
            help_df = pd.DataFrame(help_data)
            help_df.to_excel(writer, sheet_name='ë„ì›€ë§', index=False)
            self.style_header(writer, 'ë„ì›€ë§', help_df)
            self.auto_adjust_columns(writer, 'ë„ì›€ë§', help_df)
            self.log("âœ… 'ë„ì›€ë§' ì‹œíŠ¸ ìƒì„± ì™„ë£Œ")

        output.seek(0)
        self.log("ğŸ‰ ê²°ê³¼ íŒŒì¼ ìƒì„± ì™„ë£Œ!")
        return output

def main():
    # í—¤ë”
    st.markdown("""
        <div class="main-header">
            <h1>ğŸ“Š SNSì„¼í„° ì±„íŒ…ë¶„ì„ í”„ë¡œê·¸ë¨ v1.9</h1>
            <p>ì±„íŒ… ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ìƒë‹´ì‚¬ì˜ í˜‘ì—… ì„±ê³¼ë¥¼ í‰ê°€í•©ë‹ˆë‹¤</p>
        </div>
    """, unsafe_allow_html=True)

    analyzer = CollaborationAnalyzer()

    # ë©”ì¸ í˜ì´ì§€ì— íƒ­ êµ¬ì„±
    tab1, tab2, tab3 = st.tabs(["ğŸ“¤ ë¶„ì„ ì„¤ì •", "ğŸ“Š ë¶„ì„ ì‹¤í–‰", "ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ"])
    
    with tab1:
        st.markdown('<div class="card">', unsafe_allow_html=True)
        st.markdown('<div class="card-header">ğŸ“ 1ë‹¨ê³„: íŒŒì¼ ì—…ë¡œë“œ</div>', unsafe_allow_html=True)
        
        uploaded_file = st.file_uploader(
            "ì—‘ì…€ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
            type=['xlsx'],
            help="UserChat data, Message data, Manager data ì‹œíŠ¸ê°€ í¬í•¨ëœ ì—‘ì…€ íŒŒì¼",
            key="file_uploader"
        )
        
        if uploaded_file:
            st.success(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {uploaded_file.name}")
        st.markdown('</div>', unsafe_allow_html=True)
        
        # 2ê°œ ì»¬ëŸ¼ìœ¼ë¡œ ë‚ ì§œì™€ ê´€ë¦¬ì ì„¤ì •
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown('<div class="card">', unsafe_allow_html=True)
            st.markdown('<div class="card-header">ğŸ“… 2ë‹¨ê³„: ë¶„ì„ ê¸°ê°„ ì„¤ì •</div>', unsafe_allow_html=True)
            
            start_date = st.date_input(
                "ì‹œì‘ì¼",
                value=datetime(2025, 7, 1),
                format="YYYY-MM-DD",
                key="start_date"
            )
            
            end_date = st.date_input(
                "ì¢…ë£Œì¼",
                value=datetime.now() - timedelta(days=1),
                format="YYYY-MM-DD",
                key="end_date"
            )
            
            # ê¸°ê°„ ê³„ì‚° í‘œì‹œ
            if start_date and end_date:
                days = (end_date - start_date).days + 1
                st.info(f"ğŸ“Š ë¶„ì„ ê¸°ê°„: {days}ì¼")
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col2:
            st.markdown('<div class="card">', unsafe_allow_html=True)
            st.markdown('<div class="card-header">ğŸ‘¥ 3ë‹¨ê³„: ì¸ì› ì„¤ì •</div>', unsafe_allow_html=True)
            
            managers = st.text_area(
                "ê´€ë¦¬ì ëª©ë¡ (ì‰¼í‘œë¡œ êµ¬ë¶„)",
                value="ì´ë¯¼ì£¼, ì´ì¢…ë¯¼, ìœ¤ë„ìš°ë¦¬, ê¹€ì‹œì§„, ì†ì§„ìš°",
                height=60,
                key="managers"
            )
            
            exclusions = st.text_area(
                "ì œì™¸í•  ì´ë¦„ (ì‰¼í‘œë¡œ êµ¬ë¶„, ì„ íƒì‚¬í•­)",
                value="ì±„ì£¼ì€, ì •ìš©ìš±, í•œìŠ¹ìœ¤, ê¹€ì¢…í˜„",
                height=60,
                key="exclusions"
            )
            st.markdown('</div>', unsafe_allow_html=True)
    
    with tab2:
        st.markdown('<div class="card">', unsafe_allow_html=True)
        st.markdown('<div class="card-header">ğŸš€ ë¶„ì„ ì‹¤í–‰</div>', unsafe_allow_html=True)
        
        # ì„¤ì • ìš”ì•½
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ğŸ“ íŒŒì¼", "âœ… ì—…ë¡œë“œë¨" if uploaded_file else "âŒ ë¯¸ì—…ë¡œë“œ")
        with col2:
            if 'start_date' in locals() and 'end_date' in locals():
                days = (end_date - start_date).days + 1
                st.metric("ğŸ“… ë¶„ì„ ê¸°ê°„", f"{days}ì¼")
            else:
                st.metric("ğŸ“… ë¶„ì„ ê¸°ê°„", "ë¯¸ì„¤ì •")
        with col3:
            if 'managers' in locals():
                manager_count = len([m.strip() for m in managers.split(',') if m.strip()])
                st.metric("ğŸ‘¥ ê´€ë¦¬ì ìˆ˜", f"{manager_count}ëª…")
            else:
                st.metric("ğŸ‘¥ ê´€ë¦¬ì ìˆ˜", "ë¯¸ì„¤ì •")
        
        st.divider()
        
        # ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            analyze_button = st.button(
                "ğŸ¯ ë¶„ì„ ì‹œì‘",
                type="primary",
                use_container_width=True,
                disabled=not uploaded_file
            )
        
        # ì§„í–‰ ìƒí™© í‘œì‹œ
        if analyze_button:
            if not uploaded_file:
                st.error("âš ï¸ íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!")
            else:
                st.session_state.log_messages = []
                st.session_state.processing = True
                
                progress_bar = st.progress(0)
                status_text = st.empty()
                log_container = st.container()
                
                with st.spinner("ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš” â³"):
                    # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                    progress_bar.progress(10)
                    status_text.text("ğŸ“ ì„¤ì • í™•ì¸ ì¤‘...")
                    
                    # ê´€ë¦¬ì ë° ì œì™¸ ëª…ë‹¨ íŒŒì‹±
                    managers_list = [name.strip() for name in managers.split(',') if name.strip()]
                    exclusion_list = [name.strip() for name in exclusions.split(',') if name.strip()]
                    
                    progress_bar.progress(30)
                    status_text.text("ğŸ“Š ë°ì´í„° ë¡œë”© ì¤‘...")
                    
                    # ë°ì´í„° ì²˜ë¦¬
                    processed_data = analyzer.load_and_process_data(
                        uploaded_file,
                        start_date.strftime("%Y-%m-%d"),
                        end_date.strftime("%Y-%m-%d")
                    )
                    
                    progress_bar.progress(60)
                    status_text.text("ğŸ” ë¶„ì„ ìˆ˜í–‰ ì¤‘...")
                    
                    if processed_data:
                        # ê²°ê³¼ ìƒì„±
                        progress_bar.progress(80)
                        status_text.text("ğŸ“ ê²°ê³¼ íŒŒì¼ ìƒì„± ì¤‘...")
                        
                        result_file = analyzer.create_output_excel(
                            processed_data,
                            start_date.strftime("%Y-%m-%d"),
                            end_date.strftime("%Y-%m-%d"),
                            managers_list,
                            exclusion_list
                        )
                        
                        progress_bar.progress(100)
                        status_text.text("âœ… ë¶„ì„ ì™„ë£Œ!")
                        
                        st.session_state.analysis_complete = True
                        st.session_state.result_file = result_file
                        st.session_state.processing = False
                        
                        st.success("ğŸ‰ ë¶„ì„ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                        st.balloons()
                
                # ë¡œê·¸ í‘œì‹œ
                with log_container:
                    if st.session_state.log_messages:
                        st.markdown('<div class="log-box">', unsafe_allow_html=True)
                        for log in st.session_state.log_messages:
                            st.text(log)
                        st.markdown('</div>', unsafe_allow_html=True)
        
        elif not uploaded_file:
            st.info("ğŸ“Œ ë¶„ì„ì„ ì‹œì‘í•˜ë ¤ë©´ ë¨¼ì € íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    with tab3:
        st.markdown('<div class="card">', unsafe_allow_html=True)
        st.markdown('<div class="card-header">ğŸ“¥ ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ</div>', unsafe_allow_html=True)
        
        if st.session_state.analysis_complete and st.session_state.result_file:
            # ê²°ê³¼ ìš”ì•½
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("""
                    <div class="info-box">
                        <h4>ğŸ“Œ ìƒì„±ëœ ì‹œíŠ¸ ëª©ë¡</h4>
                        <ul>
                            <li>ğŸ“Š ìŠ¤ì½”ì–´ë³´ë“œ</li>
                            <li>ğŸ“‹ ì±„íŒ…ë¶„ì„_ìš”ì•½</li>
                            <li>ğŸ‘” ê´€ë¦¬ì_ë¶„ì„</li>
                            <li>ğŸ“ˆ ì±„íŒ…ë¶„ì„_ì§€í‘œ</li>
                            <li>ğŸ’¬ ìƒì„¸ ë©”ì‹œì§€ ë‚´ì—­ (ë„ì›€/ë‹´ë‹¹)</li>
                            <li>â“ ë„ì›€ë§</li>
                        </ul>
                    </div>
                """, unsafe_allow_html=True)
            
            with col2:
                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"SNSì„¼í„°_ì±„íŒ…ë¶„ì„_ê²°ê³¼_{timestamp}.xlsx"
                
                st.download_button(
                    label="ğŸ’¾ ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                    data=st.session_state.result_file,
                    file_name=filename,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True,
                    type="primary"
                )
                
                st.success("âœ… ë‹¤ìš´ë¡œë“œ ì¤€ë¹„ ì™„ë£Œ!")
                
                # ì¶”ê°€ ì•¡ì…˜
                st.divider()
                col1, col2 = st.columns(2)
                with col1:
                    if st.button("ğŸ”„ ìƒˆë¡œìš´ ë¶„ì„ ì‹œì‘", use_container_width=True):
                        st.session_state.clear()
                        st.rerun()
                with col2:
                    if st.button("ğŸ“Š ë¶„ì„ ì„¤ì • ìœ ì§€", use_container_width=True):
                        st.session_state.analysis_complete = False
                        st.session_state.result_file = None
                        st.rerun()
        else:
            st.info("ğŸ“Œ ë¶„ì„ì´ ì™„ë£Œë˜ë©´ ì—¬ê¸°ì„œ ê²°ê³¼ë¥¼ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            st.markdown("""
                <div style="text-align: center; padding: 3rem;">
                    <h3 style="color: #4da6ff;">ë¶„ì„ í”„ë¡œì„¸ìŠ¤</h3>
                    <p style="color: #b3d9ff; font-size: 1.1rem;">
                        1ï¸âƒ£ íŒŒì¼ ì—…ë¡œë“œ â†’ 2ï¸âƒ£ ê¸°ê°„ ì„¤ì • â†’ 3ï¸âƒ£ ì¸ì› ì„¤ì • â†’ 4ï¸âƒ£ ë¶„ì„ ì‹¤í–‰ â†’ 5ï¸âƒ£ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
                    </p>
                </div>
            """, unsafe_allow_html=True)
        
        st.markdown('</div>', unsafe_allow_html=True)

    # í‘¸í„°
    st.divider()
    st.markdown("""
        <div style="text-align: center; color: #4da6ff; padding: 1rem;">
            <p>Â© 2025 SNSì„¼í„° ì±„íŒ…ë¶„ì„ í”„ë¡œê·¸ë¨ v1.9 | Powered by Streamlit</p>
            <p style="font-size: 0.9rem; color: #666;">ì•„ì •ë‹¹ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ì¦ˆ</p>
        </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
